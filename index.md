![](images/cover_3.jpg)
*Face the Mountain. Isle of Skye. 2022*

---


[Google Scholar](https://scholar.google.com/citations?user=liSP4cEAAAAJ&hl=en) / [Semantic Scholar](https://www.semanticscholar.org/author/Yao-Fu/46956602) / [Github](https://github.com/FranxYao) / [Twitter](https://twitter.com/Francis_YAO_) / [LinkedIn](https://www.linkedin.com/in/yao-fu-281847b5/) / [Instagram](https://www.instagram.com/franx_yao/) / [Galary](galary.md)

Yao Fu угдт░Д. yao.fu@ed.ac.uk

I am a Ph.D. student at the University of Edinburgh (2020-) with professor [Mirella Lapata](https://homepages.inf.ed.ac.uk/mlap/). 
I finished my M.S. at Columbia University (2018-2020) with professor [John Cunningham](https://stat.columbia.edu/~cunningham/) and my B.S. at Peking University (2013-2018) with professor [Yansong Feng](https://sites.google.com/site/ysfeng/home). 
Before Ph.D., I spent great time visiting professor [Alexander Rush](http://rush-nlp.com/) at Cornell University (2019-2020). 


I study probabilistic models for human language.

I build generative models guided by Bayesian principles, powered by large language models, exploiting efficient inference, and grounded to real-world language scenarios. 

My research is equally distributed into Probabilistic Machine Learning and Natural Language Processing. Usually, NLP people think I'm doing ML while ML people think I'm doing NLP. My publications cover the following topics: 
* NLP: Language Generation; Linguistic Structure Prediction
* ML: Generative Models with Discrete Structures; Efficient Inference Algorithms

I'm maintaining the following reading lists as research roadmaps:
* Deep Generative Models for Natural Language Processing. ([github](https://github.com/franxyao/Deep-Generative-Models-for-Natural-Language-Processing))
* Compositional Generalization in Natural Language Processing. ([github](https://github.com/FranxYao/Compositional-Generalization-in-Natural-Language-Processing))

-----
### Preprints
* [Arvix 2022] _Latent Topology Induction for Understanding Contextualized Representations_. [[paper](https://arxiv.org/abs/2206.01512)]
  * __Yao Fu__ and Mirella Lapata
  * Discover a latent network within the representation space of large language models.

-----

### Publications
* [ICML 2022] _Scaling Structured Inference with Randomization_. [[paper](https://arxiv.org/abs/2112.03638)][[code](https://github.com/FranxYao/RDP)]
  * __Yao Fu__, John P. Cunningham and Mirella Lapata
  *  A family of randomized dynamic programming algorithms for scaling up classical structured prediction algorithms of different inferences (partition, marginal, entropy, reparameterization) of structures (chains, trees, and general sum-product).
* [TACL 2022] _Data-to-text Generation with Variational Sequential Planning_.[[paper](https://arxiv.org/abs/2202.13756)][[code](https://github.com/ratishsp/data2text-seq-plan-py)]
  * Ratish Puduppully, __Yao Fu__, Mirella Lapata
  * A latent planning model for generating very long document.
* [NAACL 2021] _Noisy Labeled NER with Confidence Estimation_. [[paper](https://arxiv.org/abs/2104.04318)][[code](https://github.com/liukun95/Noisy-NER-Confidence-Estimation)]
  * Kun Liu\*, __Yao Fu__\*, Chuanqi Tan, Mosha Chen, Ningyu Zhang, Songfang Huang and Sheng Gao. \*Equal contribution.
  * A confidence estimation method for estimating label noise in NER annotations and a training method based on partial marginalization according to estimated noise.
* [ICLR 2021] _Probing BERT in Hyperbolic Spaces_. [[paper](https://openreview.net/forum?id=17VnwXYZyhH)][[code](https://github.com/FranxYao/PoincareProbe)]
  * Boli Chen\*, __Yao Fu__\*, Guangwei Xu, Pengjun Xie, Chuanqi Tan, Mosha Chen, Liping Jing. \*Equal contribution. 
  * A Poincare probe for recovering hierarchical structures from contextualized representations. Applied to probing syntax and sentiment in BERT. 
* [ICLR 2021] _Prototypical Representation Learning for Relation Extraction_. [[paper](https://openreview.net/forum?id=aCgLmfhIy_f)][[code](https://github.com/Alibaba-NLP/ProtoRE)]
  * Ning Ding, Xiaobin Wang, __Yao Fu__, Guangwei Xu, Rui Wang, Pengjun Xie, Ying Shen, Fei Huang, Hai-Tao Zheng, Rui Zhang
  * A representation learning method for embedding relation prototypes on hyperspheres. Applied to supervised, semi-supervised, and few-shot relational learning. 
* [AAAI 2021] _Nested Named Entity Recognition with Partially Observed TreeCRFs_. [[paper](https://arxiv.org/abs/2012.08478)][[code](https://github.com/FranxYao/Partially-Observed-TreeCRFs)]
   *  __Yao Fu__\*, Chuanqi Tan\*, Mosha Chen, Songfang Huang, Fei Huang. \*Equal contribution. 
   * A Masked Inside algorithm for efficient partial marginalization of TreeCRFs. Applied to Nested NER.
* [NeurIPS 2020] _Latent Template Induction with Gumbel-CRFs_. [[paper](https://arxiv.org/abs/2011.14244)][[code](https://github.com/FranxYao/Gumbel-CRF)]
   * __Yao Fu__, Chuanqi Tan, Mosha Chen, Bin Bi, Yansong Feng and Alexander Rush. 
   * A Gumbel-FFBS algorithm for reparameterizing and relaxing CRFs. Applied to controllable text generation with latent templates.
* [NeurIPS 2019] _Paraphrase Generation with Latent Bag of Words_. [[paper](https://arxiv.org/abs/2001.01941)][[code](https://github.com/FranxYao/dgm_latent_bow)]
   * **Yao Fu**, Yansong Feng and John Cunningham. 
   * A differentiable planning and realization model with latent bag of words by Gumbel-topK reparameterization. Applied to paraphrase generation.
* [INLG 2019] _Rethinking Text Attribute Transfer: A Lexical Analysis_. [[paper](https://arxiv.org/abs/1909.12335)][[code](https://github.com/FranxYao/pivot_analysis)]
   * **Yao Fu**, Hao Zhou, Jiaze Chen and Lei Li. 
   * A series of text mining algorithms for discovering words with strong influence on classification. Applied to analysing text attribute transfer models. 
* [NAACL 2018] _Natural Answer Generation with Heterogeneous Memory_. [[paper](https://www.aclweb.org/anthology/N18-1017/)]
   * **Yao Fu** and Yansong Feng. 
   * An attention mechanism fusing information from different source of knowledge. Applied to answer sentence generation.

-----

### Teaching 

* Peking University. Empirical Methods for Natural Language Processing. 2022 Spring. 
  * Guest lecture on Text Generation. Tought by Yansong Feng.
* University of Edinburgh. Natural Language Understanding. 2022 Spring. 
  * Teaching Assistant. Tought by Alexandra Birch, Frank Keller, and Laura Perez.
* University of Edinburgh. [Probabilistic Modeling and Reasoning](http://www.inf.ed.ac.uk/teaching/courses/pmr/21-22/). 2022 Spring. 
  * Teaching Assistant. Tought by Michael Gutmann.
* Peking University. Empirical Methods for Natural Language Processing. 2021 Spring. 
  * Guest lecture on Text Generation. Tought by Yansong Feng.
* Alibaba DAMO Academy. Advanced Probabilistic Machine Learning Seminar. 2020 Spring. 
  * Instructor. 
* Columbia University. [COMS 4995 Applied Machine Learning](http://www.cs.columbia.edu/~amueller/comsw4995s19/), 2019 Spring.
  * Course Assistant. Tought by Andreas Muller. 


-----

### Resources and Tutorials 

* [Why S4 is Good at Long Sequence: Remembering a Sequence with Online Function Approximation](https://yaofu.notion.site/Why-S4-is-Good-at-Long-Sequence-Remembering-a-Sequence-with-Online-Function-Approximation-836fc54a49aa413b84997a265132f13f). Feb 2022. 
* Deep Structured Prediction: Inference, Reparameterization and Applications. Jun 2021 [[pdf](https://github.com/FranxYao/franxyao.github.io/blob/master/blog/bytedance%20structured%20prediction%20pub.pdf)]
* How to write Variational Inference and Generative Models for NLP: a recipe. Mar 2021 [[pdf](https://github.com/FranxYao/Deep-Generative-Models-for-Natural-Language-Processing/blob/master/src/VI4NLP_Recipe.pdf)]

-----

### Internships
* Jul 22 - Sep 22. Allen Institute for Artificial Intelligence. Research Intern. Seattle. 
  * with Dr. [Tushar Khot](https://scholar.google.com/citations?user=_8mkIjgAAAAJ&hl=en)
* Jan 20 - Oct 20. Alibaba Damo Academy. Research Intern. Beijing and Hangzhou
  * with Dr. [Chuanqi Tan](https://scholar.google.com/citations?user=tOfo4ncAAAAJ&hl=zh-CN) and [Mosha Chen](https://scholar.google.com/citations?user=6bTGGDAAAAAJ&hl=en)
* May 19 - Aug 19. Tencent AI Lab. Research Intern. Seattle
  * with Dr. [Kun Xu](https://sites.google.com/view/kunxu/home) and Dr. [Dong Yu](https://sites.google.com/view/dongyu888/)
* Dec 17 - Aug 18. Bytedance AI Lab. Research Intern. Beijing
  * with Prof. [Hao Zhou](https://scholar.google.com/citations?user=q3WaozcAAAAJ&hl=en) and Prof. [Lei Li](https://scholar.google.com/citations?user=BYXqAlwAAAAJ&hl=en)





